# ğŸƒ ShuffleNet-Replication PyTorch Implementation

This repository contains a replication of **ShuffleNet**, based on the paper **â€œShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devicesâ€**, using PyTorch. The model is designed for **lightweight and efficient image classification**, using **pointwise group convolutions** and **channel shuffle operations**.

- Implemented **ShuffleNet** using **modular ShuffleNet units** with **pointwise group convolution** and **channel shuffle** to maintain efficiency while preserving accuracy.

- Architecture:  
**Stem â†’ Stage2 â†’ Stage3 â†’ Stage4 â†’ GlobalAvgPool â†’ Flatten â†’ FC**

> **Note on channel shuffling:** Channel shuffle ensures cross-group information flow. Our implementation strictly follows the paper, maintaining **group convolution â†’ channel shuffle â†’ depthwise conv** sequence for each unit.

**Paper reference:** [ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices](https://arxiv.org/abs/1707.01083) ğŸŒ€


---

## ğŸ–¼ Overview â€“ ShuffleNet Architecture

![Overview](images/figmix.jpg)  

**Figure 1:** Illustration of group convolution + channel shuffle concept (crossâ€‘group information flow).  
**Figure 2:** Structure of a ShuffleNet unit (pointwise group conv â†’ channel shuffle â†’ depthwise conv) and downsampling (stride = 2) variant.  

## ğŸ“‹ Model Parameters â€“ Table 1  

Refer to **Table 1** in `images/figmix.jpg` for detailed layer/ stage configuration: channel counts, group settings (g), repeats per stage, output sizes.  

> **Model overview:**  
> ShuffleNet achieves high efficiency by combining **pointwise group convolution** and **channel shuffle**, allowing information mixing across groups while keeping computation low. Depthwise convolutions reduce FLOPs, and repeated units maintain representational power without increasing model size significantly.

---

## ğŸ— Project Structure

```bash
ShuffleNet/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ layers/
â”‚   â”‚   â”œâ”€â”€ conv1_layer.py            # Initial 3x3 conv layer
â”‚   â”‚   â”œâ”€â”€ flatten_layer.py          # Flatten layer
â”‚   â”‚   â”œâ”€â”€ fc_layer.py               # Fully connected layer
â”‚   â”‚   â”œâ”€â”€ pool_layers/
â”‚   â”‚   â”‚   â”œâ”€â”€ maxpool_layer.py      # MaxPool
â”‚   â”‚   â”‚   â””â”€â”€ avgpool_layer.py      # AdaptiveAvgPool
â”‚   â”‚   â”œâ”€â”€ channel_shuffle.py        # Channel shuffle operation
â”‚   â”‚
â”‚   â”œâ”€â”€ blocks/
â”‚   â”‚   â””â”€â”€ shufflenet_unit.py        # ShuffleNet unit combining group conv, shuffle, depthwise conv
â”‚   â”‚
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â””â”€â”€ shufflenet.py             # Full ShuffleNet model combining Stem + Stages
â”‚   â”‚
â”‚   â””â”€â”€ config.py                      # Input size, num_classes, groups, stage channels
â”‚
â”œâ”€â”€ images/
â”‚   â””â”€â”€ figmix.jpg                     # Figures and table 1
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```
---

## ğŸ”— Feedback

For questions or feedback, contact: [barkin.adiguzel@gmail.com](mailto:barkin.adiguzel@gmail.com)
